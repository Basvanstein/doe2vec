{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"DoE2Vec DoE2Vec is a self-supervised approach to learn exploratory landscape analysis features from design of experiments. The model can be used for downstream meta-learning tasks such as learninig which optimizer works best on a given optimization landscape. Or to classify optimization landscapes in function groups. The approach uses randomly generated functions and can also be used to find a \"cheap\" reference function given a DOE. The model uses Sobol sequences as the default sampling method. A custom sampling method can also be used. Both the samples and the landscape should be scaled between 0 and 1. Install package via pip ` pip install doe2vec ` Afterwards you can use the package via: from doe2vec import doe_model Load a model from the HuggingFace Hub Available models can be viewed here: https://huggingface.co/BasStein A model name is build up like BasStein/doe2vec-d2-m8-ls16-VAE-kl0.001 Where d is the number of dimensions, 8 the number (2^8) of samples, 16 the latent size, VAE the model type (variational autoencoder) and 0.001 the KL loss weight. Example code of loading a huggingface model obj = doe_model ( 2 , 8 , n = 50000 , latent_dim = 16 , kl_weight = 0.001 , use_mlflow = False , model_type = \"VAE\" ) obj . load_from_huggingface () #test the model obj . plot_label_clusters_bbob () How to Setup your Environment for Development python3.8 -m venv env source ./env/bin/activate pip install -r requirements.txt Generate the Data Set To generate the artificial function dataset for a given dimensionality and sample size run the following code from doe2vec inport doe_model obj = doe_model ( d , m , n = 50000 , latent_dim = latent_dim ) if not obj . load (): obj . generateData () obj . compile () obj . fit ( 100 ) obj . save () Where d is the number of dimensions, m the number of samples (2^ m ) per DOE, n the number of functions generated and latent_dim the size of the output encoding vector. Once a data set and encoder has been trained it can be loaded with the load() function.","title":"DoE2Vec"},{"location":"#install-package-via-pip","text":"` pip install doe2vec ` Afterwards you can use the package via: from doe2vec import doe_model","title":"Install package via pip"},{"location":"#load-a-model-from-the-huggingface-hub","text":"Available models can be viewed here: https://huggingface.co/BasStein A model name is build up like BasStein/doe2vec-d2-m8-ls16-VAE-kl0.001 Where d is the number of dimensions, 8 the number (2^8) of samples, 16 the latent size, VAE the model type (variational autoencoder) and 0.001 the KL loss weight. Example code of loading a huggingface model obj = doe_model ( 2 , 8 , n = 50000 , latent_dim = 16 , kl_weight = 0.001 , use_mlflow = False , model_type = \"VAE\" ) obj . load_from_huggingface () #test the model obj . plot_label_clusters_bbob ()","title":"Load a model from the HuggingFace Hub"},{"location":"#how-to-setup-your-environment-for-development","text":"python3.8 -m venv env source ./env/bin/activate pip install -r requirements.txt","title":"How to Setup your Environment for Development"},{"location":"#generate-the-data-set","text":"To generate the artificial function dataset for a given dimensionality and sample size run the following code from doe2vec inport doe_model obj = doe_model ( d , m , n = 50000 , latent_dim = latent_dim ) if not obj . load (): obj . generateData () obj . compile () obj . fit ( 100 ) obj . save () Where d is the number of dimensions, m the number of samples (2^ m ) per DOE, n the number of functions generated and latent_dim the size of the output encoding vector. Once a data set and encoder has been trained it can be loaded with the load() function.","title":"Generate the Data Set"},{"location":"contributing/","text":"Contributing First off, thanks for taking the time to contribute! File an issue to notify the maintainers about what you're working on. Fork the repo, develop and test your code changes, add docs. Make sure that your commit messages clearly describe the changes. Send a pull request. File an Issue Use the issue tracker to start the discussion. It is possible that someone else is already working on your idea, your approach is not quite right, or that the functionality exists already. The ticket you file in the issue tracker will be used to hash that all out. Style Guides Write in UTF-8 in Python 3 User modular architecture to group similar functions, classes, etc. Always use 4 spaces for indentation (don't use tabs) Try to limit line length to 80 characters Class names should always be capitalized Function names should always be lowercase Look at the existing style and adhere accordingly Fork the Repository Be sure to add the relevant tests before making the pull request. Docs will be updated automatically when we merge to master , but you should also build the docs yourself and make sure they're readable. Make the Pull Request Once you have made all your changes, tests, and updated the documentation, make a pull request to move everything back into the main branch of the repository . Be sure to reference the original issue in the pull request. Expect some back-and-forth with regards to style and compliance of these rules. Building binaries (for developers) If you want to build the executables yourself you can use the following commands. We use pyinstaller to package the executables. Make sure you have pyinstaller installed using pip install pyinstaller . On your operating system, build the exe once you have the python source code up and running: pyinstaller --distpath dist/darwin/ GSAreport.spec We provide binaries for Linux and Mac-OS in the releases section.","title":"How to contribute"},{"location":"contributing/#contributing","text":"First off, thanks for taking the time to contribute! File an issue to notify the maintainers about what you're working on. Fork the repo, develop and test your code changes, add docs. Make sure that your commit messages clearly describe the changes. Send a pull request.","title":"Contributing"},{"location":"contributing/#file-an-issue","text":"Use the issue tracker to start the discussion. It is possible that someone else is already working on your idea, your approach is not quite right, or that the functionality exists already. The ticket you file in the issue tracker will be used to hash that all out.","title":"File an Issue"},{"location":"contributing/#style-guides","text":"Write in UTF-8 in Python 3 User modular architecture to group similar functions, classes, etc. Always use 4 spaces for indentation (don't use tabs) Try to limit line length to 80 characters Class names should always be capitalized Function names should always be lowercase Look at the existing style and adhere accordingly","title":"Style Guides"},{"location":"contributing/#fork-the-repository","text":"Be sure to add the relevant tests before making the pull request. Docs will be updated automatically when we merge to master , but you should also build the docs yourself and make sure they're readable.","title":"Fork the Repository"},{"location":"contributing/#make-the-pull-request","text":"Once you have made all your changes, tests, and updated the documentation, make a pull request to move everything back into the main branch of the repository . Be sure to reference the original issue in the pull request. Expect some back-and-forth with regards to style and compliance of these rules.","title":"Make the Pull Request"},{"location":"contributing/#building-binaries-for-developers","text":"If you want to build the executables yourself you can use the following commands. We use pyinstaller to package the executables. Make sure you have pyinstaller installed using pip install pyinstaller . On your operating system, build the exe once you have the python source code up and running: pyinstaller --distpath dist/darwin/ GSAreport.spec We provide binaries for Linux and Mac-OS in the releases section.","title":"Building binaries (for developers)"},{"location":"installation/","text":"Installing using pip DoE2Vec is a python package that you can easily install via pip. Install python 3.7+ pip3 install doe2vec Installation for development To further help develop the DOE2vec package you can clone this repository and install all requirements Clone the git repo install requirements pip3 install -f requirements.txt","title":"Installation"},{"location":"installation/#installing-using-pip","text":"DoE2Vec is a python package that you can easily install via pip. Install python 3.7+ pip3 install doe2vec","title":"Installing using pip"},{"location":"installation/#installation-for-development","text":"To further help develop the DOE2vec package you can clone this repository and install all requirements Clone the git repo install requirements pip3 install -f requirements.txt","title":"Installation for development"},{"location":"license/","text":"MIT License Copyright (c) 2022 Bas van Stein Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.","title":"License"},{"location":"doe2vec/doe_model/","text":"doe_model source doe_model ( dim , m , n = 250000 , latent_dim = 32 , seed_nr = 0 , kl_weight = 0.001 , custom_sample = None , use_mlflow = False , mlflow_name = 'Doc2Vec' , model_type = 'VAE' ) Methods: .load_from_huggingface source . load_from_huggingface ( repo = 'BasStein' ) Load a pre-trained model from a HuggingFace repository. Args repo (str, optional) : the huggingface repo to load from. .loadModel source . loadModel ( dir = 'models' ) Load a pre-trained Doe2vec model. Args dir (str, optional) : The directory where the model is stored. Defaults to \"models\". Returns bool : True if loaded, else False. .loadData source . loadData ( dir = 'data' ) Load a stored functions file and retrieve all the landscapes. Args dir (str, optional) : The directory where the data are stored. Defaults to \"data\". Returns bool : True if loaded, else False. .getSample source . getSample () Get the sample DOE used. Returns array : Sample .generateData source . generateData () Generate the random functions for training the autoencoder. Returns array : array with evaluated random functions on sample. .setData source . setData ( Y ) Helper function to load the data and split in train validation sets. Args Y (nd array) : the data set to use. .compile source . compile () Compile the autoencoder architecture. .fit source . fit ( epochs = 100 , ** kwargs ) Fit the autoencoder model. Args epochs (int, optional) : Number of epochs to train. Defaults to 100. kwargs (dict, optional) : optional arguments for the fit procedure. .fitNN source . fitNN () Fit the neirest neighbour tree to find similar functions. .getNeighbourFunction source . getNeighbourFunction ( features ) Get the closest random generated function depending on a set of features (from another function). Args features (array) : Feature vector (given by the encode() function) Returns tuple : random function string, distance .save source . save ( model_dir = 'model' , data_dir = 'data' ) Save the model and random functions used for training Args model_dir (str, optional) : Directory to store the model. Defaults to \"model\". data_dir (str, optional) : Directory to store the random functions. Defaults to \"data\". .saveModel source . saveModel ( model_dir ) Save the model Args model_dir (str, optional) : Directory to store the model. Defaults to \"model\". .saveData source . saveData ( data_dir = 'data' ) Save the random functions used for training Args data_dir (str, optional) : Directory to store the random functions. Defaults to \"data\". .encode source . encode ( X ) Encode a Design of Experiments. Args X (array) : The DOE to encode. Returns array : encoded feature vector. .summary source . summary () Get a summary of the autoencoder model .plot_label_clusters_bbob source . plot_label_clusters_bbob () .visualizeTestData source . visualizeTestData ( n = 5 ) Get a visualisation of the validation data. Args n (int, optional) : The number of validation DOEs to show. Defaults to 5.","title":"Class reference"},{"location":"doe2vec/doe_model/#_1","text":"","title":""},{"location":"doe2vec/doe_model/#doe_model","text":"source doe_model ( dim , m , n = 250000 , latent_dim = 32 , seed_nr = 0 , kl_weight = 0.001 , custom_sample = None , use_mlflow = False , mlflow_name = 'Doc2Vec' , model_type = 'VAE' ) Methods:","title":"doe_model"},{"location":"doe2vec/doe_model/#load_from_huggingface","text":"source . load_from_huggingface ( repo = 'BasStein' ) Load a pre-trained model from a HuggingFace repository. Args repo (str, optional) : the huggingface repo to load from.","title":".load_from_huggingface"},{"location":"doe2vec/doe_model/#loadmodel","text":"source . loadModel ( dir = 'models' ) Load a pre-trained Doe2vec model. Args dir (str, optional) : The directory where the model is stored. Defaults to \"models\". Returns bool : True if loaded, else False.","title":".loadModel"},{"location":"doe2vec/doe_model/#loaddata","text":"source . loadData ( dir = 'data' ) Load a stored functions file and retrieve all the landscapes. Args dir (str, optional) : The directory where the data are stored. Defaults to \"data\". Returns bool : True if loaded, else False.","title":".loadData"},{"location":"doe2vec/doe_model/#getsample","text":"source . getSample () Get the sample DOE used. Returns array : Sample","title":".getSample"},{"location":"doe2vec/doe_model/#generatedata","text":"source . generateData () Generate the random functions for training the autoencoder. Returns array : array with evaluated random functions on sample.","title":".generateData"},{"location":"doe2vec/doe_model/#setdata","text":"source . setData ( Y ) Helper function to load the data and split in train validation sets. Args Y (nd array) : the data set to use.","title":".setData"},{"location":"doe2vec/doe_model/#compile","text":"source . compile () Compile the autoencoder architecture.","title":".compile"},{"location":"doe2vec/doe_model/#fit","text":"source . fit ( epochs = 100 , ** kwargs ) Fit the autoencoder model. Args epochs (int, optional) : Number of epochs to train. Defaults to 100. kwargs (dict, optional) : optional arguments for the fit procedure.","title":".fit"},{"location":"doe2vec/doe_model/#fitnn","text":"source . fitNN () Fit the neirest neighbour tree to find similar functions.","title":".fitNN"},{"location":"doe2vec/doe_model/#getneighbourfunction","text":"source . getNeighbourFunction ( features ) Get the closest random generated function depending on a set of features (from another function). Args features (array) : Feature vector (given by the encode() function) Returns tuple : random function string, distance","title":".getNeighbourFunction"},{"location":"doe2vec/doe_model/#save","text":"source . save ( model_dir = 'model' , data_dir = 'data' ) Save the model and random functions used for training Args model_dir (str, optional) : Directory to store the model. Defaults to \"model\". data_dir (str, optional) : Directory to store the random functions. Defaults to \"data\".","title":".save"},{"location":"doe2vec/doe_model/#savemodel","text":"source . saveModel ( model_dir ) Save the model Args model_dir (str, optional) : Directory to store the model. Defaults to \"model\".","title":".saveModel"},{"location":"doe2vec/doe_model/#savedata","text":"source . saveData ( data_dir = 'data' ) Save the random functions used for training Args data_dir (str, optional) : Directory to store the random functions. Defaults to \"data\".","title":".saveData"},{"location":"doe2vec/doe_model/#encode","text":"source . encode ( X ) Encode a Design of Experiments. Args X (array) : The DOE to encode. Returns array : encoded feature vector.","title":".encode"},{"location":"doe2vec/doe_model/#summary","text":"source . summary () Get a summary of the autoencoder model","title":".summary"},{"location":"doe2vec/doe_model/#plot_label_clusters_bbob","text":"source . plot_label_clusters_bbob ()","title":".plot_label_clusters_bbob"},{"location":"doe2vec/doe_model/#visualizetestdata","text":"source . visualizeTestData ( n = 5 ) Get a visualisation of the validation data. Args n (int, optional) : The number of validation DOEs to show. Defaults to 5.","title":".visualizeTestData"}]}